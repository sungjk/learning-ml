{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input => Conv1 => Pooling1 => Conv2 => Pooling2 => Fully-connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-8aa486bed8ab>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1]) # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Conv layer imgIn shape=(?, 28, 28, 1): N개의 28x28 이미지 흑/백\n",
    "# filter: 3x3, 흑/백, 32개\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "\n",
    "# Conv -> Lelu -> Pooling\n",
    "# Conv -> (?, 28, 28, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(L1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1)\n",
    "# Pool -> (?, 14, 14, 32)\n",
    "# strides: 2x2 => output: 14x14\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Conv layer 2 imgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "# Conv -> (?, 14, 14, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(L2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "print(L2)\n",
    "# Pool -> (?, 7, 7, 64)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(L2)\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "print(L2_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-8fa901dc4319>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final FC 7x7x64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "# 출력의 값과 동일하게\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost: 0.345624178\n",
      "Epoch: 0002 cost: 0.091800820\n",
      "Epoch: 0003 cost: 0.068341240\n",
      "Epoch: 0004 cost: 0.056286761\n",
      "Epoch: 0005 cost: 0.046985533\n",
      "Epoch: 0006 cost: 0.040991215\n",
      "Epoch: 0007 cost: 0.036612940\n",
      "Epoch: 0008 cost: 0.032727912\n",
      "Epoch: 0009 cost: 0.027864520\n",
      "Epoch: 0010 cost: 0.024687044\n",
      "Epoch: 0011 cost: 0.021981100\n",
      "Epoch: 0012 cost: 0.020160543\n",
      "Epoch: 0013 cost: 0.016726402\n",
      "Epoch: 0014 cost: 0.015177160\n",
      "Epoch: 0015 cost: 0.013261351\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost:', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning finished!\n",
      "Accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "print('Learning finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [9]\n",
      "Prediction: [9]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print('Label:', sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print('Prediction:', sess.run(tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r+1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN20lEQVR4nO3df6hc9ZnH8c/HXxjSImZzDdFGrxskIIKmjHFBKS6yRQNi+o/UP6qi7K2QQAslbHARBQNR2bQqaCGu2nTpWiOtGFQ0rgloEaqjxJgorlkTqUlMbogSzR8a47N/3GO5xjvfuZkzv+LzfsFl5p5nzpzHk/vxzMx3zvk6IgTgu++EQTcAoD8IO5AEYQeSIOxAEoQdSOKkfm5s9uzZMTo62s9NAqns3LlT+/fv91S1WmG3faWk+ySdKOk/I+Ku0uNHR0fVbDbrbBJAQaPRaFnr+GW87RMlPSDpKknnS7rO9vmdPh+A3qrznn2RpO0R8X5EfCHpj5Ku6U5bALqtTtjPkvS3Sb9/WC37Bttjtpu2m+Pj4zU2B6COnn8aHxFrIqIREY2RkZFebw5AC3XCvkvSvEm//6BaBmAI1Qn7a5LOs32u7VMk/VTS+u60BaDbOh56i4gvbS+T9Lwmht4eiYhtXesMQFfVGmePiGclPdulXgD0EF+XBZIg7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlas7hi+O3du7dYf/7554v1u+++u1jfvXt3sb5ly5aWtXnz5hXXRXfVCrvtnZI+lXRE0pcR0ehGUwC6rxtH9n+OiP1deB4APcR7diCJumEPSRtsv257bKoH2B6z3bTdHB8fr7k5AJ2qG/bLIuKHkq6StNT2j45+QESsiYhGRDRGRkZqbg5Ap2qFPSJ2Vbf7JD0paVE3mgLQfR2H3fZM29//+r6kH0va2q3GAHRXnU/j50h60vbXz/PfEfFcV7pK5siRI8X6xo0bi/Ubb7yxZe3QoUPFdQ8ePFis13XhhRe2rL355pvFdRmH766Owx4R70tq/S8JYKgw9AYkQdiBJAg7kARhB5Ig7EASnOLaB1988UWxvmLFimL93nvv7XjbZ599drG+ZMmSYv2TTz4p1tevX9/x+u1On73//vuL9RNO4Fh1LNhbQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+xd8Pnnnxfrt912W7FeZxxdklatWtWydtNNNxXXbXf1oP37y9cSveCCC4r1ffv2taw9+OCDxXUXLSpfC+X6668v1vFNHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAlHRN821mg0otls9m17/bJjx45iff78+bWef9myZcX6fffd17JWXeq7Z9pdDnrhwoUdP/eCBQuK9XZ/SzNnzux428erRqOhZrM55T86R3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILz2YfAjBkzivXly5cX670eSy/p5bTK7777brHe7nr8GcfZS9oe2W0/Ynuf7a2Tls2y/YLt96rb03vbJoC6pvMy/neSrjxq2QpJL0bEeZJerH4HMMTahj0iXpJ04KjF10haW91fK6k8hxCAgev0A7o5EbGnuv+RpDmtHmh7zHbTdnN8fLzDzQGoq/an8TFxJk3Ls2kiYk1ENCKi0e7ihgB6p9Ow77U9V5Kq29aXEAUwFDoN+3pJN1T3b5D0VHfaAdArbcfZbT8m6XJJs21/KOl2SXdJWmf7ZkkfSLq2l00Ou+eee67W+qecckqx3sux7Lpuv/32QbeAaWob9oi4rkXpii73AqCH+LoskARhB5Ig7EAShB1IgrADSXCKaxfUHXq7+uqru9RJ/61cubJYf+CBB/rUCdrhyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOPk3btm1rWduwYUOt5z7nnHNqrT9Ig7yMNY4NR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9mmaP39+y9qiRYuK67788svF+qpVq4r1TZs2Feulc8bPOOOM4rpz584t1ts56aTyn9C5557bsrZjx45a28ax4cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj5Np556asvaPffcU1x38eLFxfrHH39crL/yyivF+sKFC1vWzjzzzOK6l156abHezmmnnVasl/7buaZ8f7U9stt+xPY+21snLbvD9i7bm6uf8l8zgIGbzsv430m6corlv4mIi6qfZ7vbFoBuaxv2iHhJ0oE+9AKgh+p8QLfM9pbqZf7prR5ke8x203ZzfHy8xuYA1NFp2H8rab6kiyTtkbS61QMjYk1ENCKiMTIy0uHmANTVUdgjYm9EHImIryQ9JKl82heAgeso7LYnnxf5E0lbWz0WwHBoO85u+zFJl0uabftDSbdLutz2RZJC0k5JP+9hj0PvkksuKdbbzd9+xRVXFOufffbZMff0td27dxfr69atK9bbXRc+Imqtj/5pG/aIuG6KxQ/3oBcAPcTXZYEkCDuQBGEHkiDsQBKEHUiCU1z74OKLLy7WX3311WJ969by1xg2btzYsvboo48W1/3qq6+K9cOHDxfrDK0dPziyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASbneKYjc1Go1oNpt92x7aO3CgfHnB1atbXoRIkrR9+/Zi/Yknnjjmnqbr6aefLtbbXcL7u6jRaKjZbE755QeO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOezJzdr1qxi/c477yzW231PY8GCBS1rK1euLK7bTruprvFNHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2VF0wgn1jgfLly9vWas7zl4aw8e3tf2XtD3P9ibbb9veZvsX1fJZtl+w/V51e3rv2wXQqen8b/tLSb+KiPMl/ZOkpbbPl7RC0osRcZ6kF6vfAQyptmGPiD0R8UZ1/1NJ70g6S9I1ktZWD1sraUmvmgRQ3zG9IbM9KmmhpL9KmhMRe6rSR5LmtFhnzHbTdnN8fLxGqwDqmHbYbX9P0p8k/TIiDk6uxcTZEFOeERERayKiERGNkZGRWs0C6Ny0wm77ZE0E/Q8R8edq8V7bc6v6XEn7etMigG5oO/TmiTl5H5b0TkT8elJpvaQbJN1V3T7Vkw5xXJsxY0bPnvuhhx4q1huNRs+2fTyazjj7pZJ+Jukt25urZbdqIuTrbN8s6QNJ1/amRQDd0DbsEfEXSVNedF7SFd1tB0Cv8HVZIAnCDiRB2IEkCDuQBGEHkuAUVxy3Dh48WKwfPny4Ze3kk0/udjtDjyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBODsGZubMmcX6oUOHivXHH3+8WF+1alXL2ujoaHHd7yKO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPs6KmTTmr9J7Z69eriurfcckutbT/zzDMta0uXLq313McjjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMR05mefJ+n3kuZICklrIuI+23dI+ldJ49VDb42IZ3vVKL57xsbGatVxbKbzpZovJf0qIt6w/X1Jr9t+oar9JiL+o3ftAeiW6czPvkfSnur+p7bfkXRWrxsD0F3H9J7d9qikhZL+Wi1aZnuL7Udsn95inTHbTdvN8fHxqR4CoA+mHXbb35P0J0m/jIiDkn4rab6kizRx5J/yi84RsSYiGhHRGBkZ6ULLADoxrbDbPlkTQf9DRPxZkiJib0QciYivJD0kaVHv2gRQV9uw27akhyW9ExG/nrR87qSH/UTS1u63B6BbpvNp/KWSfibpLdubq2W3SrrO9kWaGI7bKennPekQQFdM59P4v0jyFCXG1IHjCN+gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI6N/G7HFJH0xaNFvS/r41cGyGtbdh7Uuit051s7dzImLK67/1Nezf2rjdjIjGwBooGNbehrUvid461a/eeBkPJEHYgSQGHfY1A95+ybD2Nqx9SfTWqb70NtD37AD6Z9BHdgB9QtiBJAYSdttX2n7X9nbbKwbRQyu2d9p+y/Zm280B9/KI7X22t05aNsv2C7bfq26nnGNvQL3dYXtXte822148oN7m2d5k+23b22z/olo+0H1X6Ksv+63v79ltnyjpfyX9i6QPJb0m6bqIeLuvjbRge6ekRkQM/AsYtn8k6TNJv4+IC6pl90g6EBF3Vf+jPD0i/m1IertD0meDnsa7mq1o7uRpxiUtkXSjBrjvCn1dqz7st0Ec2RdJ2h4R70fEF5L+KOmaAfQx9CLiJUkHjlp8jaS11f21mvhj6bsWvQ2FiNgTEW9U9z+V9PU04wPdd4W++mIQYT9L0t8m/f6hhmu+95C0wfbrtscG3cwU5kTEnur+R5LmDLKZKbSdxrufjppmfGj2XSfTn9fFB3TfdllE/FDSVZKWVi9Xh1JMvAcbprHTaU3j3S9TTDP+d4Pcd51Of17XIMK+S9K8Sb//oFo2FCJiV3W7T9KTGr6pqPd+PYNudbtvwP383TBN4z3VNOMagn03yOnPBxH21ySdZ/tc26dI+qmk9QPo41tsz6w+OJHtmZJ+rOGbinq9pBuq+zdIemqAvXzDsEzj3WqacQ143w18+vOI6PuPpMWa+ET+/yT9+yB6aNHXP0p6s/rZNujeJD2miZd1hzXx2cbNkv5B0ouS3pP0P5JmDVFv/yXpLUlbNBGsuQPq7TJNvETfImlz9bN40Puu0Fdf9htflwWS4AM6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUji/wESAi2f5ByF9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
