{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# 학습할 때와 다르게 테스트할 때는 1로 설정\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"dropout/mul_1:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "# Conv -> (?, 28, 28, 32)\n",
    "# Pool -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(L1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(L1)\n",
    "L1 = tf.nn.dropout(L1, rate=keep_prob)\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"dropout_1/mul_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "# Conv -> (?, 14, 14, 64)\n",
    "# Pool -> (?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(L2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "print(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(L2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "print(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"dropout_2/mul_1:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"dropout_2/mul_1:0\", shape=(?, 4, 4, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "# Conv -> (?, 7, 7, 128)\n",
    "# Pool -> (?, 4, 4, 128)\n",
    "# Reshape -> (?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(L3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "print(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(L3)\n",
    "L3 = tf.nn.dropout(L3, rate=keep_prob)\n",
    "print(L3)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "print(L3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
      "Tensor(\"dropout_3/mul_1:0\", shape=(?, 625), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "print(L4)\n",
    "L4 = tf.nn.dropout(L4, rate=keep_prob)\n",
    "print(L4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.773599622\n",
      "Epoch: 0002 cost = 0.279511101\n",
      "Epoch: 0003 cost = 0.204791427\n",
      "Epoch: 0004 cost = 0.171918431\n",
      "Epoch: 0005 cost = 0.157201430\n",
      "Epoch: 0006 cost = 0.146468318\n",
      "Epoch: 0007 cost = 0.138015665\n",
      "Epoch: 0008 cost = 0.129929279\n",
      "Epoch: 0009 cost = 0.123464354\n",
      "Epoch: 0010 cost = 0.118836618\n",
      "Epoch: 0011 cost = 0.116371491\n",
      "Epoch: 0012 cost = 0.111011962\n",
      "Epoch: 0013 cost = 0.111066220\n",
      "Epoch: 0014 cost = 0.108282619\n",
      "Epoch: 0015 cost = 0.103254842\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Finished!\n",
      "Accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [2]\n",
      "Prediction:  [0]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
